{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "The network we built in the previous part isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
    "\n",
    "앞서 우리가 만든 네트워크는 별로 똑똑하지 않습니다. 비선형 활성화를 가진 신경망은 universal function approximator처럼 수행됩니다. \n",
    "\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "처음 만든 네트워크는 나이브합니다 - 이 네트워크는 인풋을 아웃풋으로 맵핑하는 함수를 전혀 모르는 상태죠. 우리는 이 네트워크를 실제 데이터의 예를 보여주면서 트레이닝을 시키면서 이 네트워크가 함수를 적절히 근사할 수 있도록 네트워크 parameter를 적절히 최적화시킵니다.\n",
    "\n",
    "이 parameter를 찾기 위해, 우리는 네트워크가 실제 아웃풋을 얼마나 허접하게 예측하는지 알 필요가 있어요. 이를 위해 **loss function**(=cost)을 계산합니다. 이것은 prediction error를 측정한 것입니다. 예를 들어, mean squared loss 수식이 regression 회귀나 binary classification 문제에서 다음과 같이 사용됩니다.\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "위에서, $n$은 training 데이터의 숫자를 의미,\n",
    "$y_i$는 실제 label 값을 의미,\n",
    "$\\hat{y}_i$는 예측된 label 값을 의미합니다.\n",
    "\n",
    "\n",
    "네트워크 parameter 설정에 따른 loss를 최소화함으로써, 우리는 loss가 최소일때의 configuration을 찾을 수 있고, 네트워크는 비로소 올바른 label값을 높은 정확도로 예측할 수 있게 됩니다. 우리는 이 최소값을 **gradient descent**라는 process를 통해 찾습니다. gradient란 loss 함수와 좌표 상에서 가장 빠른 변화를 보이는 방향의 기울기를 뜻합니다. 가장 적은 시간을 들여 최소값을 찾기 위해서는, 아래 방향의 gradient를 따라갈 필요가 있습니다. 이건 마치 가장 가파른 능선을 따라서 산을 내려오는 것과 같습니다. \n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "backpropagation\n",
    "\n",
    "하나의 layer network를 위해서, gradient descent는 구현하기 간단합니다. 그러나, 더 깊은, multilayer의 신경망에서는 훨씬 복잡하죠. 너무 복잡한 나머지 연구자들이 어떻게 이 multilayer network를 학습시키는 방법을 알아내는 데 30년이나 걸렸습니다. \n",
    "\n",
    "이 다중층의 네트워크를 **backpropagation**을 통해 학습시킵니다. backpropatation은 calculus를 적용한 chain rule을 적용한 것입니다. 두개의 layer 네트워크를 그래프로 나타내서 이해를 쉽게 만들어 보겠습니다. \n",
    "\n",
    "<img src='assets/backprop_diagram.png' width=550px>\n",
    "\n",
    "**부가설명**  : **forward: x->y,l**  , **backward: l->w**  위 그림을 보면, forward pass는 처음의 input x가 L1과 L2라는 두 layer를 거쳐서 output인 y로 나오는 것입니다. 이 때 예측된 y와 실제 y 사이의 차이로써 계산된 loss가 함께 나옵니다. backward pass는 loss를 다시 네트워크의 뒤로 후방 이동하면서, gradient를 구합니다. 우선 L2를 만나면서 loss는 L2로 미분된 gradient 값을 갖습니다. 즉, L2의 weight 및 b2에 대한 loss의 기울기를 구하는 거죠. 그리고 나서 loss는 signoid값 s를 만납니다. loss를 S로 미분한 gradient를 구합니다. 이 값은, L2를 S로 미분한 gradient와 loss를 L2로 미분한 gradient를 곱한 값과 같습니다. 같은 원리를 통해, loss를 W1로 미분한 weight를 구할 수 있습니다. \n",
    "\n",
    "\n",
    "네트워크를 통한 forward pass에서는, 우리 데이터와 계산은 bottom에서 top으로 진행합니다. 우리는 $x$라는 input을 linear transformation인 L1에 통과시키면서 W1 weight와 b1 bias를 부여합니다. 그러고 나서 output은 sigmoid 함수인 S를 거치고 또다른 transformation인 L2를 거칩니다. 마지막으로 우리는 loss를 계산합니다. 이때 네트워크의 예측력이 얼마나 구렸는지를 측정하는 거죠. 우리의 다음 목표는 weight와 bias를 조정해서 loss를 최소화하는 겁니다. \n",
    "\n",
    "gradient descent를 가지고 weight을 학습하기 위해서, 우리는 loss의 gradient를 **뒤쪽으로(backwards) propagage**합니다.각각의 식은 input과 output 사이에 gradient를 가지고 있습니다. 우리가 gradient를 뒤로 보냄에 따라, 우리는 오는 gradient를 다른 gradient와 곱하게 됩니다. 수학적으로, 이건 단순히 loss의 gradient를 체인 룰에 따라 weight들과 계산하는 것입니다. \n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "\n",
    "**부가설명** 위에서 본 바와 같이, backproparagtion을 통해 loss를 W1로 미분한 gradient를 구했다. 그리고 우리는 이 값을 활용하여 우리의 weight를 다음과 같이 update한다.\n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "The learning rate $\\alpha$ is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses in PyTorch\n",
    "\n",
    "Let's start by seeing how we calculate the loss with PyTorch. Through the `nn` module, PyTorch provides losses such as the cross-entropy loss (`nn.CrossEntropyLoss`). You'll usually see the loss assigned to `criterion`. As noted in the last part, with a classification problem such as MNIST, we're using the softmax function to predict class probabilities. With a softmax output, you want to use cross-entropy as the loss. To actually calculate the loss, you first define the criterion then pass in the output of your network and the correct labels.\n",
    "\n",
    "Something really important to note here. Looking at [the documentation for `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class.\n",
    ">\n",
    "> The input is expected to contain scores for each class.\n",
    "\n",
    "This means we need to pass in the raw output of our network into the loss, not the output of the softmax function. This raw output is usually called the *logits* or *scores*. We use the logits because softmax gives you probabilities which will often be very close to zero or one but floating-point numbers can't accurately represent values near zero or one ([read more here](https://docs.python.org/3/tutorial/floatingpoint.html)). It's usually best to avoid doing calculations with probabilities, typically we use log-probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 9, 7, 5, 2, 3, 0, 1, 7, 8, 1, 5, 3, 3, 8, 7, 8, 3, 6, 1, 3, 9, 2, 0,\n",
       "        7, 1, 1, 3, 4, 1, 3, 8, 8, 1, 2, 4, 0, 0, 8, 5, 0, 9, 1, 9, 1, 4, 8, 2,\n",
       "        8, 9, 1, 3, 2, 2, 6, 9, 3, 7, 3, 3, 3, 2, 8, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3285, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images) #model.forward(images)와 결과가 같음\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-softmax output `nn.LogSoftmax`를 사용하거나, `F.log_softmax`을 가지고 모델을 build하는게 더 편리할 수 있다. \n",
    "([documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax))\n",
    "\n",
    "그리고 나서 exponential `torch.exp(output)`을 사용해서 실제 확률을 얻을 수 있다. \n",
    "\n",
    "log-softmax output을 가지고, 당신은 negative log likelihood loss를 사용하고 싶다면, \n",
    "`nn.NLLLoss` ([documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)). \n",
    "\n",
    "\n",
    ">**Exercise:** Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3074, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "이제 우리는 loss를 계산할 줄 안다. 그럼 backpropagation은 어떻게 할까? `autograd`라는 모듈을 통해 tensor의 gradient를 자동으로 계산할 수 있다. 우리는 우리의 모든 parameter를 loss에 대해 gradient를 계산할 수 있다. Autograd는 tensor에 대해 일하는 모든 operation을 추적하면서 일한다. 그리고 나서 이 operation을 backward로 이동하면서, gradient를 계산한다. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "gradient는 어떤 변수 z에 대해 `z.backward()`로 계산할 수 있다. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1889,  0.2691],\n",
      "        [ 0.6837, -0.3170]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4134, 0.0724],\n",
      "        [0.4674, 0.1005]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the operation that created `y`, a power operation `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f37d05522b0>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5134, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the gradients for `x` and `y` but they are empty currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5944,  0.1345],\n",
      "        [ 0.3418, -0.1585]])\n",
      "tensor([[ 0.5944,  0.1345],\n",
      "        [ 0.3418, -0.1585]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 gradients 계산들은 특히 뉴럴 네트워크에서 유용하다. 트레이닝을 위해서 우리는 weight의 gradient를 cost에 대해서 필요로 한다. pytorch를 가지고 network를 통해 forward로 데이터를 돌려서 loss를 계산한다음, 다시 backward로 loss에 대해 gradient를 계산한다. gradient를 한번 얻으면 gradient descent step을 하나 밟을 수 있게 된다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Autograd together\n",
    "\n",
    "모든 parameter는 `required_grad=True`와 함께 초기화된다. 이는 우리가 loss를 계산하고 `loss.backward()`를 할때, parameter에 대한 gradient가 계산된다는 것이다. 이 gradient들은 weight을 업데이트하는데 사용된다. Below you can see an example of calculating the gradients using a backwards pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-2.6873e-03, -2.6873e-03, -2.6873e-03,  ..., -2.6873e-03,\n",
      "         -2.6873e-03, -2.6873e-03],\n",
      "        [ 2.9660e-03,  2.9660e-03,  2.9660e-03,  ...,  2.9660e-03,\n",
      "          2.9660e-03,  2.9660e-03],\n",
      "        [-1.4336e-03, -1.4336e-03, -1.4336e-03,  ..., -1.4336e-03,\n",
      "         -1.4336e-03, -1.4336e-03],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.5079e-03, -1.5079e-03, -1.5079e-03,  ..., -1.5079e-03,\n",
      "         -1.5079e-03, -1.5079e-03],\n",
      "        [ 6.2282e-05,  6.2282e-05,  6.2282e-05,  ...,  6.2282e-05,\n",
      "          6.2282e-05,  6.2282e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html). For example we can use stochastic gradient descent with `optim.SGD`. You can see how to define an optimizer below.\n",
    "\n",
    "optimizer를 통해 우리는 weight를 gradient를 가지고 업데이트 할 겁니다. 우리는 PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html).를 가지고 할 수 있습니다. 예를 들어 `optim.SGD`는 stochastic gradient descent를 쓸 수 있게 합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network \n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes. Note that I have a line of code `optimizer.zero_grad()`. When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means that you need to zero the gradients on each training pass or you'll retain gradients from previous training batches.\n",
    "\n",
    "우리는 이제 어떻게 각각의 파트를 사용하는지 알기 때문에 어떻게 일을하는지 한번 보겠습니다. 일단 한번의 learning step을 생각해보죠.\n",
    "\n",
    "* forward pass를 만듭니다.\n",
    "* network output을 사용해서 loss를 계산합니다.\n",
    "* `loss.backward()`를 가지고 backward pass를 하여 gradient를 계산합니다.\n",
    "* optimizer를 가지고 weight를 업데이트 합니다. \n",
    "\n",
    "아래에 나는 traing step을 한번 해서 weight와 gradient를 프린트할 겁니다. 나는 `optimizer.zero_grad()`를 가집니다. 같은 parameter로 여러개의 backward pass를 갈때, gradient는 축적됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 8.3754e-03, -2.0521e-02, -1.9366e-02,  ...,  3.1858e-02,\n",
      "         -6.3661e-05,  2.5013e-02],\n",
      "        [-1.6706e-02, -1.0046e-02,  1.6179e-02,  ..., -1.9457e-02,\n",
      "         -2.0707e-02,  1.6371e-02],\n",
      "        [ 3.0229e-03, -6.9682e-05,  1.0186e-02,  ...,  1.9762e-02,\n",
      "          2.6056e-02,  4.7374e-03],\n",
      "        ...,\n",
      "        [-2.7845e-02,  2.8455e-02,  2.7274e-02,  ..., -1.1720e-02,\n",
      "         -3.4397e-03,  1.4524e-03],\n",
      "        [ 9.6314e-03,  2.3491e-02,  1.6331e-03,  ...,  1.0681e-03,\n",
      "          2.6836e-02, -2.2966e-02],\n",
      "        [ 3.2810e-02, -9.7161e-03, -2.2147e-02,  ...,  2.5784e-02,\n",
      "         -2.5290e-02,  1.2240e-02]], requires_grad=True)\n",
      "Gradient - tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "print('Gradient -', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient - tensor([[ 0.0032,  0.0032,  0.0032,  ...,  0.0032,  0.0032,  0.0032],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005]])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 8.3110e-03, -2.0585e-02, -1.9431e-02,  ...,  3.1794e-02,\n",
      "         -1.2805e-04,  2.4949e-02],\n",
      "        [-1.6695e-02, -1.0035e-02,  1.6190e-02,  ..., -1.9447e-02,\n",
      "         -2.0696e-02,  1.6382e-02],\n",
      "        [ 3.0730e-03, -1.9633e-05,  1.0236e-02,  ...,  1.9812e-02,\n",
      "          2.6107e-02,  4.7874e-03],\n",
      "        ...,\n",
      "        [-2.7851e-02,  2.8450e-02,  2.7268e-02,  ..., -1.1726e-02,\n",
      "         -3.4451e-03,  1.4470e-03],\n",
      "        [ 9.6544e-03,  2.3514e-02,  1.6562e-03,  ...,  1.0911e-03,\n",
      "          2.6859e-02, -2.2943e-02],\n",
      "        [ 3.2801e-02, -9.7253e-03, -2.2156e-02,  ...,  2.5774e-02,\n",
      "         -2.5299e-02,  1.2230e-02]], requires_grad=True)\n",
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0163,  0.0008,  0.0490,  ..., -0.0340, -0.0760,  0.0069],\n",
      "        [-0.0628,  0.0517, -0.0470,  ...,  0.0693,  0.0074, -0.0443],\n",
      "        [-0.0435, -0.0276, -0.0333,  ..., -0.0723,  0.0260,  0.0784],\n",
      "        ...,\n",
      "        [-0.0009, -0.0045,  0.0565,  ...,  0.0086,  0.0535, -0.0073],\n",
      "        [-0.0121, -0.0858,  0.0111,  ...,  0.0504, -0.0760, -0.0782],\n",
      "        [-0.0529, -0.0451, -0.0460,  ..., -0.0484,  0.0276, -0.0231]],\n",
      "       requires_grad=True)\n",
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0381,  0.0151, -0.0333, -0.0950, -0.0169,  0.0957, -0.0530, -0.0596,\n",
      "          0.0120, -0.0084,  0.0998, -0.0013,  0.0434, -0.0755,  0.0871,  0.0545,\n",
      "         -0.0477, -0.1161,  0.0334, -0.0553,  0.0558,  0.1056, -0.0543, -0.0720,\n",
      "          0.1222, -0.0505, -0.1015,  0.0350, -0.0481,  0.0192, -0.0487, -0.1136,\n",
      "         -0.0548, -0.0142,  0.0384, -0.0862,  0.1103,  0.0199, -0.1032,  0.1161,\n",
      "          0.0203,  0.0648,  0.0525,  0.0113, -0.0703,  0.0416,  0.0935,  0.0041,\n",
      "          0.0917, -0.0253,  0.0396, -0.0259, -0.0629,  0.0716, -0.0200,  0.0166,\n",
      "         -0.0148, -0.0900, -0.0095, -0.0561,  0.0814, -0.0980, -0.0274,  0.1000],\n",
      "        [ 0.1131,  0.0225, -0.1114,  0.0582,  0.0830, -0.0602,  0.0606,  0.1176,\n",
      "          0.0070, -0.0687, -0.0568, -0.0764,  0.1096, -0.0124,  0.0750,  0.0870,\n",
      "         -0.0477,  0.1175,  0.0310,  0.0772,  0.0674,  0.0496, -0.0762,  0.0851,\n",
      "         -0.0935,  0.0848,  0.0216,  0.0931, -0.1224,  0.0136, -0.0210, -0.0909,\n",
      "          0.0665,  0.0023, -0.0449,  0.0252, -0.0890, -0.0461,  0.0354, -0.1234,\n",
      "          0.0255,  0.0260,  0.0825, -0.1096, -0.0316, -0.1047, -0.0419,  0.0391,\n",
      "         -0.1110, -0.0948,  0.0091,  0.0546,  0.1002,  0.0414, -0.0908,  0.1135,\n",
      "         -0.0077,  0.1131, -0.0895,  0.0704, -0.0269,  0.0998,  0.0798,  0.0421],\n",
      "        [-0.0080, -0.0578, -0.0358, -0.0730,  0.0853, -0.0362,  0.0329, -0.0518,\n",
      "          0.0531,  0.0578,  0.0783,  0.0864, -0.1202,  0.0222, -0.0128,  0.0712,\n",
      "          0.0579, -0.0563,  0.0965, -0.0222,  0.0643, -0.0270,  0.0102,  0.0800,\n",
      "          0.0761,  0.0427, -0.0910,  0.0939, -0.0826, -0.0726, -0.0558,  0.0872,\n",
      "         -0.0140, -0.0098,  0.0884, -0.0846,  0.0784, -0.0015,  0.0835, -0.0406,\n",
      "         -0.0026, -0.0099, -0.0003,  0.0887, -0.0372,  0.0044,  0.1132, -0.0189,\n",
      "          0.0800,  0.0531,  0.1108,  0.0173, -0.0857, -0.0726, -0.0688,  0.0102,\n",
      "         -0.0726, -0.0042, -0.0687, -0.0018,  0.0508,  0.0224, -0.0082,  0.0110],\n",
      "        [ 0.1165, -0.0326,  0.0294,  0.0172, -0.0703, -0.0627, -0.0574, -0.0469,\n",
      "         -0.0323,  0.1165, -0.0155,  0.0593, -0.0981, -0.0086,  0.0734, -0.0170,\n",
      "         -0.0794,  0.0338,  0.0781,  0.0955, -0.0774, -0.0228, -0.0020,  0.0792,\n",
      "          0.0261,  0.0966, -0.0147, -0.0720, -0.0324, -0.1006,  0.0098,  0.0312,\n",
      "          0.0320, -0.0872, -0.0161,  0.1110,  0.1149, -0.0666, -0.0656,  0.0043,\n",
      "         -0.0496,  0.1206, -0.0003,  0.0397, -0.1215, -0.0757, -0.0307, -0.0970,\n",
      "         -0.0563, -0.1248,  0.0367, -0.0839,  0.1022, -0.0665,  0.0492, -0.0792,\n",
      "         -0.1065, -0.1198, -0.0778, -0.1000, -0.0119,  0.0049, -0.1193,  0.1238],\n",
      "        [ 0.0210, -0.0677,  0.0974, -0.0710,  0.1029, -0.1004,  0.0526,  0.0015,\n",
      "          0.0302, -0.0833, -0.1143, -0.1097, -0.0768,  0.0865, -0.0291, -0.0563,\n",
      "         -0.0540, -0.0850, -0.0259,  0.0172, -0.0721, -0.0040,  0.1006,  0.0978,\n",
      "          0.0267, -0.1165,  0.0680, -0.1051,  0.0111,  0.0245,  0.1102, -0.0917,\n",
      "         -0.0593,  0.0500,  0.1072,  0.0367,  0.0399, -0.0584,  0.0853, -0.0845,\n",
      "         -0.0607,  0.0588, -0.0248, -0.0763, -0.0559, -0.0755,  0.1086, -0.1145,\n",
      "          0.1243, -0.0492, -0.0831, -0.0180, -0.1146, -0.0671,  0.0041,  0.1040,\n",
      "         -0.0004, -0.0693, -0.0773,  0.0852,  0.0086, -0.1248, -0.0129, -0.1214],\n",
      "        [-0.0734, -0.0632, -0.0262, -0.1136,  0.0761, -0.0423, -0.0886,  0.0459,\n",
      "         -0.0910,  0.1210,  0.0876, -0.0321, -0.1169, -0.0747,  0.0679,  0.0836,\n",
      "         -0.0528,  0.0017,  0.1245,  0.0392,  0.1163,  0.0763, -0.0464, -0.0797,\n",
      "          0.1207, -0.0828, -0.0418,  0.0160, -0.0630,  0.0163, -0.0017, -0.1093,\n",
      "         -0.0492,  0.0549, -0.1018, -0.0428, -0.0945, -0.0738,  0.0814,  0.0014,\n",
      "         -0.0139, -0.0289,  0.0561, -0.0322,  0.0535,  0.1225,  0.0646, -0.0838,\n",
      "         -0.0965,  0.0249,  0.0112, -0.0854,  0.0367,  0.0728, -0.1203,  0.1018,\n",
      "         -0.0083,  0.1081, -0.0060,  0.0934,  0.0854, -0.0642, -0.0018,  0.1181],\n",
      "        [ 0.0225,  0.0206,  0.1244, -0.0132,  0.0342,  0.0350, -0.0081, -0.0216,\n",
      "          0.1021, -0.0090, -0.0816, -0.0531, -0.0360, -0.1051,  0.1101,  0.0507,\n",
      "          0.0404, -0.0993,  0.1152, -0.0860, -0.0769, -0.0366, -0.0964, -0.0979,\n",
      "          0.0345,  0.0826,  0.0754, -0.0944, -0.0478, -0.0034,  0.1195,  0.0474,\n",
      "         -0.0966, -0.0999, -0.0128, -0.0570, -0.0930,  0.1198,  0.0978, -0.1119,\n",
      "         -0.0176, -0.1204, -0.0869, -0.1244, -0.0525,  0.0849,  0.0763,  0.0363,\n",
      "          0.0305,  0.0454,  0.0824,  0.0698, -0.1011, -0.1183, -0.0198,  0.1010,\n",
      "          0.0325,  0.0585, -0.0132, -0.1199, -0.0501,  0.0931, -0.0655, -0.0462],\n",
      "        [-0.0512, -0.0364,  0.0842, -0.0202, -0.0046, -0.1034, -0.0391, -0.1051,\n",
      "          0.0433,  0.0761,  0.0805,  0.0952, -0.0657, -0.0479,  0.0033,  0.0220,\n",
      "          0.0182, -0.0712,  0.1058,  0.0807,  0.0769, -0.1133, -0.0306, -0.1051,\n",
      "         -0.0509,  0.0581, -0.1011,  0.0257,  0.0390,  0.0265, -0.0295,  0.0435,\n",
      "          0.1213, -0.0685,  0.0408,  0.0916, -0.0573, -0.0380, -0.0284, -0.0900,\n",
      "          0.0954, -0.1015,  0.0654,  0.1159, -0.1247,  0.0820, -0.0404,  0.0894,\n",
      "          0.0790,  0.0654,  0.0985,  0.0105, -0.1078, -0.0796,  0.0357, -0.0534,\n",
      "         -0.1106,  0.0624,  0.0099,  0.1114,  0.0432, -0.0568, -0.0389, -0.0346],\n",
      "        [ 0.0818,  0.0347,  0.1246,  0.1249,  0.1098, -0.0438,  0.0351,  0.1027,\n",
      "         -0.0226, -0.0838, -0.0840,  0.0704, -0.0503, -0.0875, -0.0020,  0.0075,\n",
      "         -0.0365,  0.0272, -0.0279,  0.0626, -0.0548,  0.0931, -0.1204,  0.0482,\n",
      "          0.0222,  0.1191, -0.0879, -0.0147, -0.0094, -0.0117, -0.0231, -0.0842,\n",
      "         -0.0274, -0.0838,  0.0735, -0.0473, -0.0395, -0.0174,  0.0348, -0.0905,\n",
      "         -0.0768,  0.1158,  0.0548, -0.0756, -0.1100, -0.0471,  0.0162, -0.0198,\n",
      "         -0.0842,  0.1217,  0.1006,  0.0231,  0.0069,  0.0487,  0.1092, -0.0141,\n",
      "         -0.0137, -0.0457, -0.0235,  0.0034,  0.1133,  0.0631, -0.0713, -0.0017],\n",
      "        [-0.0636, -0.0025, -0.0432, -0.1223, -0.0268,  0.1231,  0.0726,  0.1200,\n",
      "         -0.0323,  0.1032, -0.0978,  0.1108,  0.0028,  0.0482,  0.1191,  0.0510,\n",
      "         -0.0623,  0.0015,  0.0393, -0.0479, -0.0461, -0.0606,  0.0720, -0.1111,\n",
      "         -0.0003, -0.0950, -0.0953,  0.0294,  0.0790, -0.0407, -0.0855, -0.1090,\n",
      "          0.0918, -0.0867, -0.0723,  0.0075, -0.0652,  0.1047,  0.0713, -0.0091,\n",
      "          0.0117, -0.1215,  0.0828,  0.0812, -0.1187, -0.0848,  0.0112, -0.1246,\n",
      "          0.0147,  0.0726, -0.0113, -0.0081,  0.0004,  0.0790, -0.1009,  0.0437,\n",
      "          0.1103, -0.0036, -0.0328, -0.0914, -0.0716, -0.0599,  0.0153, -0.0413]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)\n",
    "print('Updated weights - ', model[2].weight)\n",
    "print('Updated weights - ', model[4].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. Some nomenclature, one pass through the entire dataset is called an *epoch*. So here we're going to loop through `trainloader` to get our training batches. For each batch, we'll doing a training pass where we calculate the loss, do a backwards pass, and update the weights.\n",
    "\n",
    "이제 이 알고리즘은 루프에 돌려서 모든 이미지에 대해서 할 것입니다. 모든 데이터셋에 대해 한번 pass하는 것을 하나의 *epoch*이라고 합니다. 여기서 우리는 `trainloader`를 통해 training batch를 받아옵니다. 각각의 배치에 대해 하나의 training pass를 해서 loss를 계산하고 backwards apss를 하여 weight 업데이트를 합니다. \n",
    "\n",
    "> **Exercise: ** Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9032056839989702\n",
      "Training loss: 0.8599407113055939\n",
      "Training loss: 0.5394276508898623\n",
      "Training loss: 0.438701564743956\n",
      "Training loss: 0.38990046137939893\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2127915322780609"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images. Next up you'll write the code for training a neural network on a more complex dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
